{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07-05: Efficient Convolution Backward Pass using col2im\n",
    "\n",
    "Try calculating with NumPy, then check with TensorFlow's autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Basic 2D Convolution\n",
    "$(4 \\times 4) * (3 \\times 3) = (2 \\times 2)$\n",
    "\n",
    "#### 2. Padding\n",
    "$(4 \\times 4) * (3 \\times 3) = (4 \\times 4)$ where $P=1$\n",
    "\n",
    "#### 3. Stride\n",
    "$(7 \\times 7) * (3 \\times 3) = (3 \\times 3)$ where $S=2$\n",
    "\n",
    "#### 4. Padding and Stride\n",
    "$(7 \\times 7) * (3 \\times 3) = (4 \\times 4)$ where $P=1, S=2$\n",
    "\n",
    "#### 5. Channel\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3) = (2 \\times 2)$\n",
    "\n",
    "#### 6. Channel and bias \n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3) + (1) = (2 \\times 2)$\n",
    "\n",
    "#### 7. Multiple Filters\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) = (2 \\times 2 \\times 4)$\n",
    "\n",
    "#### 8.Multiple Filters + bias \n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (2 \\times 2 \\times 4)$\n",
    "\n",
    "#### 9. Mini-batch + bias\n",
    "$(3 \\times 4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (3 \\times 2 \\times 2 \\times 4)$\n",
    "\n",
    "#### 10. RGB Mini-batch $*$ Multiple Filters with stride and padding\n",
    "$(3 \\times 7 \\times 7 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (3 \\times 4 \\times 4 \\times 4)$ where $P=1, S=2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def float_sequence(size):\n",
    "    return np.arange(size, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convolution Backward using col2im\n",
    "\n",
    "$(4 \\times 4) * (3 \\times 3) = (2 \\times 2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== dW ===\n",
      "[[ 10.  14.  18.]\n",
      " [ 26.  30.  34.]\n",
      " [ 42.  46.  50.]]\n",
      "=== dX_col ===\n",
      "[[ 12.  11.  10.   9.   8.   7.   6.   5.   4.]\n",
      " [ 12.  11.  10.   9.   8.   7.   6.   5.   4.]\n",
      " [ 12.  11.  10.   9.   8.   7.   6.   5.   4.]\n",
      " [ 12.  11.  10.   9.   8.   7.   6.   5.   4.]]\n",
      "=== dX ===\n",
      "[[ 12.  23.  21.  10.]\n",
      " [ 21.  40.  36.  17.]\n",
      " [ 15.  28.  24.  11.]\n",
      " [  6.  11.   9.   4.]]\n",
      "=== dX (tf) ===\n",
      "[[ 12.  23.  21.  10.]\n",
      " [ 21.  40.  36.  17.]\n",
      " [ 15.  28.  24.  11.]\n",
      " [  6.  11.   9.   4.]]\n",
      "=== dW (tf) ===\n",
      "[[ 10.  14.  18.]\n",
      " [ 26.  30.  34.]\n",
      " [ 42.  46.  50.]]\n",
      "=== Matched? ===\n",
      "dX:  True\n",
      "dW:  True\n"
     ]
    }
   ],
   "source": [
    "X = float_sequence(4*4).reshape(4,4)\n",
    "W = 12 - float_sequence(3*3).reshape(3,3)\n",
    "\n",
    "#================== Forward ==================\n",
    "# We have X_col and W_col from forward pass\n",
    "\n",
    "X_col = np.zeros((4,9))\n",
    "for h in range(2):\n",
    "    for w in range(2):\n",
    "        h_start = h\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        X_slice = X[h_start:h_end, w_start:w_end]\n",
    "        X_col_row_index = h * 2 + w\n",
    "        X_col[X_col_row_index, :] = X_slice.reshape(1, -1)\n",
    "\n",
    "W_col = W.reshape(-1, 1)\n",
    "\n",
    "\n",
    "#================== dY ==================\n",
    "dY = np.ones((2,2))\n",
    "dY_col = dY.reshape(4, 1)\n",
    "\n",
    "# print(\"=== dY ===\")\n",
    "# print(dY)\n",
    "# print(\"=== dY_col ===\")\n",
    "# print(dY_col)\n",
    "\n",
    "#================== dW ==================\n",
    "dW_col = np.dot(X_col.T, dY_col)\n",
    "dW = dW_col.reshape(3,3)\n",
    "        \n",
    "print(\"=== dW ===\")     \n",
    "print(dW)\n",
    "\n",
    "#================== dX ==================\n",
    "dX_col = np.dot(dY_col, W_col.T)\n",
    "dX = np.zeros((4,4))\n",
    "for h in range(2):\n",
    "    for w in range(2):\n",
    "        h_start = h\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        dX_col_row_index = h * 2 + w\n",
    "        dX_col_slice = dX_col[dX_col_row_index, :]\n",
    "        dX[h_start:h_end, w_start:w_end] += dX_col_slice.reshape(3, 3)\n",
    "\n",
    "\n",
    "print(\"=== dX_col ===\")     \n",
    "print(dX_col)\n",
    "\n",
    "print(\"=== dX ===\")     \n",
    "print(dX)\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 4, 4, 1))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 1, 1))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "    print(\"=== dX (tf) ===\")     \n",
    "    print(tf_dX[0, :, :, 0])\n",
    "    print(\"=== dW (tf) ===\")     \n",
    "    print(tf_dW[:, :, 0, 0])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, 0]))\n",
    "print(\"dW: \", np.all(dW == tf_dW[:, :, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convolution with padding using col2im\n",
    "\n",
    "$(4 \\times 4) * (3 \\times 3) = (4 \\times 4)$ where $P=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== dW ===\n",
      "[[  45.   66.   54.]\n",
      " [  84.  120.   96.]\n",
      " [  81.  114.   90.]]\n",
      "=== dX (tf) ===\n",
      "[[ 40.  57.  57.  36.]\n",
      " [ 51.  72.  72.  45.]\n",
      " [ 51.  72.  72.  45.]\n",
      " [ 28.  39.  39.  24.]]\n",
      "=== dW (tf) ===\n",
      "[[  45.   66.   54.]\n",
      " [  84.  120.   96.]\n",
      " [  81.  114.   90.]]\n",
      "=== Matched? ===\n",
      "dX:  True\n",
      "dW:  True\n"
     ]
    }
   ],
   "source": [
    "X_org = float_sequence(4*4).reshape(4,4)\n",
    "P = 1\n",
    "X = np.pad(X_org, ((P, P), (P, P)), 'constant')\n",
    "W = 12 - float_sequence(3*3).reshape(3,3)\n",
    "\n",
    "H_out = (4 + 2*P - 3) + 1\n",
    "W_out = (4 + 2*P - 3) + 1\n",
    "\n",
    "\n",
    "#================== Forward ==================\n",
    "X_col = np.zeros((16,9))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        X_slice = X[h_start:h_end, w_start:w_end]\n",
    "        X_col_row_index = h * H_out + w\n",
    "        X_col[X_col_row_index, :] = X_slice.reshape(1, -1)\n",
    "\n",
    "W_col = W.reshape(-1, 1)\n",
    "\n",
    "\n",
    "#================== dY ==================\n",
    "dY = np.ones((4,4))\n",
    "dY_col = dY.reshape(16, 1)\n",
    "\n",
    "\n",
    "#================== dW ==================\n",
    "dW_col = np.dot(X_col.T, dY_col)\n",
    "dW = dW_col.reshape(3,3)\n",
    "        \n",
    "print(\"=== dW ===\")     \n",
    "print(dW)\n",
    "\n",
    "#================== dX ==================\n",
    "dX_col = np.dot(dY_col, W_col.T)\n",
    "dX = np.zeros((6,6))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        dX_col_row_index = h * 2 + w\n",
    "        dX_col_slice = dX_col[dX_col_row_index, :]\n",
    "        dX[h_start:h_end, w_start:w_end] += dX_col_slice.reshape(3, 3)\n",
    "dX = dX[P:-P, P:-P]\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X_org.reshape(1, 4, 4, 1))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 1, 1))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "    print(\"=== dX (tf) ===\")     \n",
    "    print(tf_dX[0, :, :, 0])\n",
    "    print(\"=== dW (tf) ===\")     \n",
    "    print(tf_dW[:, :, 0, 0])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, 0]))\n",
    "print(\"dW: \", np.all(dW == tf_dW[:, :, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convolution with Stride using col2im\n",
    "\n",
    "$(7 \\times 7) * (3 \\times 3) = (3 \\times 3)$ where $S=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== dX (tf) ===\n",
      "[[ 12.  11.  22.  11.  22.  11.  10.]\n",
      " [  9.   8.  16.   8.  16.   8.   7.]\n",
      " [ 18.  16.  32.  16.  32.  16.  14.]\n",
      " [  9.   8.  16.   8.  16.   8.   7.]\n",
      " [ 18.  16.  32.  16.  32.  16.  14.]\n",
      " [  9.   8.  16.   8.  16.   8.   7.]\n",
      " [  6.   5.  10.   5.  10.   5.   4.]]\n",
      "=== dW (tf) ===\n",
      "[[ 144.  153.  162.]\n",
      " [ 207.  216.  225.]\n",
      " [ 270.  279.  288.]]\n",
      "=== Matched? ===\n",
      "dX:  True\n",
      "dW:  True\n"
     ]
    }
   ],
   "source": [
    "P = 0\n",
    "S = 2\n",
    "X = float_sequence(7*7).reshape(7,7)\n",
    "W = 12 - float_sequence(3*3).reshape(3,3)\n",
    "\n",
    "H_out = (7 + 2*P - 3) // S + 1\n",
    "W_out = (7 + 2*P - 3) // S + 1\n",
    "\n",
    "#================== Forward ==================\n",
    "X_col = np.zeros((H_out * W_out, 9))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        X_slice = X[h_start:h_end, w_start:w_end]\n",
    "        X_col_row_index = h * H_out + w\n",
    "        X_col[X_col_row_index, :] = X_slice.reshape(1, -1)\n",
    "W_col = W.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#================== dY ==================\n",
    "dY = np.ones((3,3))\n",
    "dY_col = dY.reshape(9, 1)\n",
    "\n",
    "\n",
    "#================== dW ==================\n",
    "dW_col = np.dot(X_col.T, dY_col)\n",
    "dW = dW_col.reshape(3,3)\n",
    "\n",
    "# print(\"=== dW ===\")     \n",
    "# print(dW)\n",
    "\n",
    "\n",
    "#================== dX ==================\n",
    "dX_col = np.dot(dY_col, W_col.T)\n",
    "dX = np.zeros((7,7))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        dX_col_row_index = h * 2 + w\n",
    "        dX_col_slice = dX_col[dX_col_row_index, :]\n",
    "        dX[h_start:h_end, w_start:w_end] += dX_col_slice.reshape(3, 3)\n",
    "\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 7, 7, 1))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 1, 1))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, S, S, 1], padding='VALID')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "    print(\"=== dX (tf) ===\")     \n",
    "    print(tf_dX[0, :, :, 0])\n",
    "    print(\"=== dW (tf) ===\")     \n",
    "    print(tf_dW[:, :, 0, 0])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, 0]))\n",
    "print(\"dW: \", np.all(dW == tf_dW[:, :, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Padding and Stride using col2im\n",
    "\n",
    "$(7 \\times 7) * (3 \\times 3) = (4 \\times 4)$ where $P=1, S=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== L (tf) ===\n",
      "19200.0\n",
      "=== dX (tf) ===\n",
      "[[  8.  16.   8.  16.   8.  16.   8.]\n",
      " [ 16.  32.  16.  32.  16.  32.  16.]\n",
      " [  8.  16.   8.  16.   8.  16.   8.]\n",
      " [ 16.  32.  16.  32.  16.  32.  16.]\n",
      " [  8.  16.   8.  16.   8.  16.   8.]\n",
      " [ 16.  32.  16.  32.  16.  32.  16.]\n",
      " [  8.  16.   8.  16.   8.  16.   8.]]\n",
      "=== dW (tf) ===\n",
      "[[ 216.  288.  216.]\n",
      " [ 288.  384.  288.]\n",
      " [ 216.  288.  216.]]\n",
      "dX:  True\n",
      "dY:  True\n"
     ]
    }
   ],
   "source": [
    "P = 1\n",
    "S = 2\n",
    "X_org = float_sequence(7*7).reshape(7,7)\n",
    "X = np.pad(X_org, ((P, P), (P, P)), 'constant')\n",
    "W = 12 - float_sequence(3*3).reshape(3,3)\n",
    "\n",
    "H_out = (7 + 2*P - 3) // S + 1\n",
    "W_out = (7 + 2*P - 3) // S + 1\n",
    "\n",
    "\n",
    "#================== Forward ==================\n",
    "X_col = np.zeros((H_out * W_out, 9))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        X_slice = X[h_start:h_end, w_start:w_end]\n",
    "        X_col_row_index = h * H_out + w\n",
    "        X_col[X_col_row_index, :] = X_slice.reshape(1, -1)\n",
    "\n",
    "W_col = W.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "#================== dY ==================\n",
    "dY = np.ones((4,4))\n",
    "dY_col = dY.reshape(16, 1)\n",
    "\n",
    "\n",
    "#================== dW ==================\n",
    "dW_col = np.dot(X_col.T, dY_col)\n",
    "dW = dW_col.reshape(3,3)\n",
    "\n",
    "# print(\"=== dW ===\")     \n",
    "# print(dW)\n",
    "\n",
    "\n",
    "#================== dX ==================\n",
    "dX_col = np.dot(dY_col, W_col.T)\n",
    "dX = np.zeros((7+2*P, 7+2*P))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        dX_col_row_index = h * 2 + w\n",
    "        dX_col_slice = dX_col[dX_col_row_index, :]\n",
    "        dX[h_start:h_end, w_start:w_end] += dX_col_slice.reshape(3, 3)\n",
    "dX = dX[P:-P, P:-P]\n",
    "\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X_org.reshape(1, 7, 7, 1))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 1, 1))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, S, S, 1], padding='SAME')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "    print(\"=== L (tf) ===\")     \n",
    "    print(tf_L_val)\n",
    "    print(\"=== dX (tf) ===\")     \n",
    "    print(tf_dX[0, :, :, 0])\n",
    "    print(\"=== dW (tf) ===\")     \n",
    "    print(tf_dW[:, :, 0, 0])\n",
    "\n",
    "# print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, 0]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Channel with col2im\n",
    "\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3) = (2 \\times 2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== L (tf) ===\n",
      "34650.0\n",
      "=== Matched? ===\n",
      "dX:  True\n",
      "dW:  True\n"
     ]
    }
   ],
   "source": [
    "P = 0\n",
    "S = 1\n",
    "X = float_sequence(4*4*3).reshape(4,4,3)\n",
    "W = 30 - float_sequence(3*3*3).reshape(3,3,3)\n",
    "\n",
    "H_out = (4 + 2*P - 3) // S + 1\n",
    "W_out = (4 + 2*P - 3) // S + 1\n",
    "\n",
    "#================== Forward ==================\n",
    "X_col = np.zeros((H_out * W_out, 3*3*3))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        X_slice = X[h_start:h_end, w_start:w_end, :].transpose(2, 0, 1)\n",
    "        X_col_row_index = h * H_out + w\n",
    "        X_col[X_col_row_index, :] = X_slice.reshape(1, -1)\n",
    "\n",
    "W_col = W.transpose(2, 0, 1).reshape(-1, 1)      \n",
    "\n",
    "\n",
    "\n",
    "#================== dY ==================\n",
    "dY = np.ones((2,2))\n",
    "dY_col = dY.reshape(4, 1)\n",
    "\n",
    "\n",
    "#================== dW ==================\n",
    "dW_col = np.dot(X_col.T, dY_col)\n",
    "dW = dW_col.reshape(3,3,3).transpose(1, 2, 0)\n",
    "\n",
    "# print(\"=== dW ===\")     \n",
    "# print(dW)\n",
    "\n",
    "\n",
    "#================== dX ==================\n",
    "dX_col = np.dot(dY_col, W_col.T)\n",
    "dX = np.zeros((4, 4, 3))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        dX_col_row_index = h * 2 + w\n",
    "        dX_col_slice = dX_col[dX_col_row_index, :]\n",
    "        dX[h_start:h_end, w_start:w_end, :] += dX_col_slice.reshape(3, 3, 3).transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 4, 4, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 1))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "    print(\"=== L (tf) ===\")     \n",
    "    print(tf_L_val)\n",
    "#     print(\"=== dX (tf) ===\")     \n",
    "#     print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, 0])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, :]))\n",
    "print(\"dW: \", np.all(dW == tf_dW[:, :, :, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Channel and bias using col2im\n",
    "\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3) + (1) = (2 \\times 2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matched? ===\n",
      "dX:  True\n",
      "dW:  True\n",
      "db:  True\n"
     ]
    }
   ],
   "source": [
    "P = 0\n",
    "S = 1\n",
    "X = float_sequence(4*4*3).reshape(4,4,3)\n",
    "W = 30 - float_sequence(3*3*3).reshape(3,3,3)\n",
    "b = np.array([10], dtype=np.float32)\n",
    "\n",
    "H_out = (4 + 2*P - 3) // S + 1\n",
    "W_out = (4 + 2*P - 3) // S + 1\n",
    "\n",
    "#================== Forward ==================\n",
    "X_col = np.zeros((H_out * W_out, 3*3*3))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        X_slice = X[h_start:h_end, w_start:w_end, :].transpose(2, 0, 1)\n",
    "        X_col_row_index = h * H_out + w\n",
    "        X_col[X_col_row_index, :] = X_slice.reshape(1, -1)\n",
    "\n",
    "W_col = W.transpose(2, 0, 1).reshape(-1, 1)      \n",
    "\n",
    "\n",
    "#================== dY ==================\n",
    "dY = np.ones((2,2))\n",
    "dY_col = dY.reshape(4, 1)\n",
    "\n",
    "#================== db ==================\n",
    "db = np.sum(dY)\n",
    "\n",
    "#================== dW ==================\n",
    "dW_col = np.dot(X_col.T, dY_col)\n",
    "dW = dW_col.reshape(3,3,3).transpose(1, 2, 0)\n",
    "\n",
    "# print(\"=== dW ===\")     \n",
    "# print(dW)\n",
    "\n",
    "#================== dX ==================\n",
    "dX_col = np.dot(dY_col, W_col.T)\n",
    "dX = np.zeros((4, 4, 3))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        dX_col_row_index = h * 2 + w\n",
    "        dX_col_slice = dX_col[dX_col_row_index, :]\n",
    "        dX[h_start:h_end, w_start:w_end, :] += dX_col_slice.reshape(3, 3, 3).transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 4, 4, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 1))\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW, tf_db = sess.run(tf_grad)\n",
    "#     print(\"=== L (tf) ===\")     \n",
    "#     print(tf_L_val)\n",
    "#     print(\"=== dX (tf) ===\")     \n",
    "#     print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, 0])\n",
    "#     print(\"=== db (tf) ===\")     \n",
    "#     print(tf_db[0])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, :]))\n",
    "print(\"dW: \", np.all(dW == tf_dW[:, :, :, 0]))\n",
    "print(\"db: \", np.all(db == tf_db[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Multiple Filters using col2im\n",
    "\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) = (2 \\times 2 \\times 4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matched? ===\n",
      "dX:  True\n",
      "dW:  True\n"
     ]
    }
   ],
   "source": [
    "P = 0\n",
    "S = 1\n",
    "X = float_sequence(4*4*3).reshape(4,4,3)\n",
    "W = 120 - float_sequence(3*3*3*4).reshape(3,3,3,4)\n",
    "\n",
    "H_out = (4 + 2*P - 3) // S + 1\n",
    "W_out = (4 + 2*P - 3) // S + 1\n",
    "\n",
    "\n",
    "#================== Foward ==================\n",
    "X_col = np.zeros((H_out * W_out, 3*3*3))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        X_slice = X[h_start:h_end, w_start:w_end, :].transpose(2, 0, 1)\n",
    "        X_col_row_index = h * H_out + w\n",
    "        X_col[X_col_row_index, :] = X_slice.reshape(1, -1)\n",
    "\n",
    "W_col = W.transpose(2, 0, 1, 3).reshape(-1, 4)\n",
    "\n",
    "\n",
    "#================== dY ==================\n",
    "dY = np.ones((2,2,4))\n",
    "dY_col = dY.reshape(4, 4)\n",
    "\n",
    "\n",
    "#================== dW ==================\n",
    "dW_col = np.dot(X_col.T, dY_col)\n",
    "dW = dW_col.reshape(3,3,3,4).transpose(1, 2, 0, 3)\n",
    "\n",
    "\n",
    "#================== dX ==================\n",
    "dX_col = np.dot(dY_col, W_col.T)\n",
    "dX = np.zeros((4, 4, 3))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        dX_col_row_index = h * 2 + w\n",
    "        dX_col_slice = dX_col[dX_col_row_index, :]\n",
    "        dX[h_start:h_end, w_start:w_end, :] += dX_col_slice.reshape(3, 3, 3).transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 4, 4, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 4))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "#     print(\"=== L (tf) ===\")     \n",
    "#     print(tf_L_val)\n",
    "#     print(\"=== dX (tf) ===\")     \n",
    "#     print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, :])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, :]))\n",
    "print(\"dW: \", np.all(dW == tf_dW[:, :, :, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Multiple Filters + bias using col2im\n",
    "\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (2 \\times 2 \\times 4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== db (tf) ===\n",
      "[ 4.  4.  4.  4.]\n",
      "=== Matched? ===\n",
      "dX:  True\n",
      "dW:  True\n",
      "db:  True\n"
     ]
    }
   ],
   "source": [
    "P = 0\n",
    "S = 1\n",
    "X = float_sequence(4*4*3).reshape(4,4,3)\n",
    "W = 120 - float_sequence(3*3*3*4).reshape(3,3,3,4)\n",
    "b = np.array([10, 100, 1000, 10000], dtype=np.float32)\n",
    "\n",
    "\n",
    "#================== Foward ==================\n",
    "X_col = np.zeros((H_out * W_out, 3*3*3))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        X_slice = X[h_start:h_end, w_start:w_end, :].transpose(2, 0, 1)\n",
    "        X_col_row_index = h * H_out + w\n",
    "        X_col[X_col_row_index, :] = X_slice.reshape(1, -1)\n",
    "\n",
    "W_col = W.transpose(2, 0, 1, 3).reshape(-1, 4)\n",
    "\n",
    "\n",
    "#================== dY ==================\n",
    "dY = np.ones((2,2,4))\n",
    "dY_col = dY.reshape(4, 4)\n",
    "\n",
    "\n",
    "#================== db ==================\n",
    "db = np.sum(dY, axis=(0,1))\n",
    "\n",
    "\n",
    "#================== dW ==================\n",
    "dW_col = np.dot(X_col.T, dY_col)\n",
    "dW = dW_col.reshape(3,3,3,4).transpose(1, 2, 0, 3)\n",
    "\n",
    "\n",
    "#================== dX ==================\n",
    "dX_col = np.dot(dY_col, W_col.T)\n",
    "dX = np.zeros((4, 4, 3))\n",
    "for h in range(H_out):\n",
    "    for w in range(W_out):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        dX_col_row_index = h * 2 + w\n",
    "        dX_col_slice = dX_col[dX_col_row_index, :]\n",
    "        dX[h_start:h_end, w_start:w_end, :] += dX_col_slice.reshape(3, 3, 3).transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 4, 4, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 4))\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW, tf_db = sess.run(tf_grad)\n",
    "#     print(\"=== L (tf) ===\")     \n",
    "#     print(tf_L_val)\n",
    "#     print(\"=== dX (tf) ===\")     \n",
    "#     print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, :])\n",
    "    print(\"=== db (tf) ===\")     \n",
    "    print(tf_db)\n",
    "\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, :]))\n",
    "print(\"dW: \", np.all(dW == tf_dW[:, :, :, :]))\n",
    "print(\"db: \", np.all(db == tf_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Mini-batch + bias using col2im\n",
    "\n",
    "$(3 \\times 4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (3 \\times 2 \\times 2 \\times 4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matched? ===\n",
      "dX:  True\n",
      "dY:  True\n",
      "db:  True\n"
     ]
    }
   ],
   "source": [
    "P = 0\n",
    "S = 1\n",
    "X = float_sequence(3*4*4*3).reshape(3,4,4,3)\n",
    "W = 120 - float_sequence(3*3*3*4).reshape(3,3,3,4)\n",
    "b = np.array([10, 100, 1000, 10000], dtype=np.float32)\n",
    "\n",
    "H_out = (4 + 2*P - 3) // S + 1\n",
    "W_out = (4 + 2*P - 3) // S + 1\n",
    "\n",
    "#================== Forward ==================\n",
    "X_col = np.zeros((3 * H_out * W_out, 3*3*3))\n",
    "for n_batch in range(3):\n",
    "    for h in range(H_out):\n",
    "        for w in range(W_out):\n",
    "            h_start = h * S\n",
    "            h_end   = h_start + 3\n",
    "            w_start = w * S\n",
    "            w_end   = w_start + 3\n",
    "\n",
    "            X_slice = X[n_batch, h_start:h_end, w_start:w_end, :].transpose(2, 0, 1)\n",
    "            X_col_row_index = n_batch * (H_out * W_out) + h * H_out + w\n",
    "#             print(\"index:\", X_col_row_index)\n",
    "            X_col[X_col_row_index, :] = X_slice.reshape(1, -1)\n",
    "\n",
    "W_col = W.transpose(2, 0, 1, 3).reshape(-1, 4)\n",
    "\n",
    "\n",
    "#================== dY ==================\n",
    "dY = np.ones((3,2,2,4))\n",
    "dY_col = dY.reshape(12, 4)\n",
    "\n",
    "#================== db ==================\n",
    "db = np.sum(dY, axis=(0,1,2))\n",
    "\n",
    "\n",
    "#================== dW ==================\n",
    "dW_col = np.dot(X_col.T, dY_col)\n",
    "dW = dW_col.reshape(3,3,3,4).transpose(1, 2, 0, 3)\n",
    "\n",
    "\n",
    "#================== dX ==================\n",
    "dX_col = np.dot(dY_col, W_col.T)\n",
    "dX = np.zeros((3, 4+2*P, 4+2*P, 3))\n",
    "for n_batch in range(3):\n",
    "    for h in range(H_out):\n",
    "        for w in range(W_out):\n",
    "            h_start = h * S\n",
    "            h_end   = h_start + 3\n",
    "            w_start = w * S\n",
    "            w_end   = w_start + 3\n",
    "\n",
    "            dX_col_row_index = n_batch * (H_out * W_out) + h * H_out + w\n",
    "            dX_col_slice = dX_col[dX_col_row_index, :]\n",
    "            \n",
    "            dX[n_batch, h_start:h_end, w_start:w_end, :] += dX_col_slice.reshape(3, 3, 3).transpose(1, 2, 0)\n",
    "\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(3, 4, 4, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 4))\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW, tf_db = sess.run(tf_grad)\n",
    "#     print(\"=== L (tf) ===\")     \n",
    "#     print(tf_L_val)\n",
    "#     print(\"=== dX (tf) ===\")     \n",
    "#     print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, :])\n",
    "#     print(\"=== db (tf) ===\")     \n",
    "#     print(tf_db)\n",
    "\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[:, :, :, :]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, :, :]))\n",
    "print(\"db: \", np.all(db == tf_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. RGB Mini-batch $*$ Multiple Filters with stride and padding\n",
    "$(3 \\times 7 \\times 7 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (3 \\times 4 \\times 4 \\times 4)$ where $P=1, S=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matched? ===\n",
      "dX:  True\n",
      "dY:  True\n",
      "db:  True\n"
     ]
    }
   ],
   "source": [
    "P = 1\n",
    "S = 2\n",
    "X_org = float_sequence(3*7*7*3).reshape(3,7,7,3)\n",
    "X = np.pad(X_org, ((0, 0), (P, P), (P, P), (0, 0)), 'constant')\n",
    "W = 120 - float_sequence(3*3*3*4).reshape(3,3,3,4)\n",
    "b = np.array([10, 100, 1000, 10000], dtype=np.float32)\n",
    "\n",
    "H_out = (7 + 2*P - 3) // S + 1\n",
    "W_out = (7 + 2*P - 3) // S + 1\n",
    "\n",
    "\n",
    "#================== Forward ==================\n",
    "X_col = np.zeros((3 * H_out * W_out, 3*3*3))\n",
    "for n_batch in range(3):\n",
    "    for h in range(H_out):\n",
    "        for w in range(W_out):\n",
    "            h_start = h * S\n",
    "            h_end   = h_start + 3\n",
    "            w_start = w * S\n",
    "            w_end   = w_start + 3\n",
    "\n",
    "            X_slice = X[n_batch, h_start:h_end, w_start:w_end, :].transpose(2, 0, 1)\n",
    "            X_col_row_index = n_batch * (H_out * W_out) + h * H_out + w\n",
    "            X_col[X_col_row_index, :] = X_slice.reshape(1, -1)\n",
    "\n",
    "W_col = W.transpose(2, 0, 1, 3).reshape(-1, 4)\n",
    "\n",
    "\n",
    "#================== dY ==================\n",
    "dY = np.ones((3,4,4,4))\n",
    "dY_col = dY.reshape(48, 4)\n",
    "\n",
    "\n",
    "#================== db ==================\n",
    "db = np.sum(dY, axis=(0,1,2))\n",
    "\n",
    "\n",
    "#================== dW ==================\n",
    "dW_col = np.dot(X_col.T, dY_col)\n",
    "dW = dW_col.reshape(3,3,3,4).transpose(1, 2, 0, 3)\n",
    "\n",
    "\n",
    "#================== dX ==================\n",
    "dX_col = np.dot(dY_col, W_col.T)\n",
    "dX = np.zeros((3, 7+2*P, 7+2*P, 3))\n",
    "for n_batch in range(3):\n",
    "    for h in range(H_out):\n",
    "        for w in range(W_out):\n",
    "            h_start = h * S\n",
    "            h_end   = h_start + 3\n",
    "            w_start = w * S\n",
    "            w_end   = w_start + 3\n",
    "\n",
    "            dX_col_row_index = n_batch * (H_out * W_out) + h * H_out + w\n",
    "            dX_col_slice = dX_col[dX_col_row_index, :]\n",
    "            \n",
    "            dX[n_batch, h_start:h_end, w_start:w_end, :] += dX_col_slice.reshape(3, 3, 3).transpose(1, 2, 0)\n",
    "\n",
    "dX = dX[:, P:-P, P:-P, :] # unpad\n",
    "\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X_org.reshape(3, 7, 7, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 4))\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, S, S, 1], padding='SAME') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW, tf_db = sess.run(tf_grad)\n",
    "#     print(\"=== L (tf) ===\")     \n",
    "#     print(tf_L_val)\n",
    "#     print(\"=== dX (tf) ===\")     \n",
    "#     print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, :])\n",
    "#     print(\"=== db (tf) ===\")     \n",
    "#     print(tf_db)\n",
    "\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[:, :, :, :]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, :, :]))\n",
    "print(\"db: \", np.all(db == tf_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized efficient convolution backward using col2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_backward(dY, X, W, b, P=0, S=1):\n",
    "    N_batch, H_in, W_in, C_in = X.shape\n",
    "    H_filter, W_filter, _, C_out = W.shape\n",
    "    _, H_out, W_out, _ = dY.shape\n",
    "    \n",
    "    if P > 0:\n",
    "        X = np.pad(X, ((0, 0), (P, P), (P, P), (0, 0)), 'constant')\n",
    "    \n",
    "    #================== forward ==================\n",
    "    X_col = np.zeros((N_batch * H_out * W_out, H_filter*W_filter*C_in))\n",
    "    X_col_row_index = 0\n",
    "    for n_batch in range(N_batch): # TODO: Maybe I can remove this loop over N_batch?\n",
    "        for h in range(H_out):\n",
    "            for w in range(W_out):\n",
    "                h_start = h * S\n",
    "                h_end   = h_start + H_filter\n",
    "                w_start = w * S\n",
    "                w_end   = w_start + W_filter\n",
    "\n",
    "                X_slice = X[n_batch, h_start:h_end, w_start:w_end, :].transpose(2, 0, 1)\n",
    "                X_col[X_col_row_index, :] = X_slice.reshape(1, -1)\n",
    "                \n",
    "                X_col_row_index += 1 # X_col_row_index = n_batch * (H_out * W_out) + h * W_out + w\n",
    "\n",
    "    W_col = W.transpose(2, 0, 1, 3).reshape(-1, C_out)\n",
    "    \n",
    "    \n",
    "    #================== dY ==================\n",
    "    dY_col = dY.reshape(-1, C_out)\n",
    "    \n",
    "    #================== db ==================\n",
    "    db = np.sum(dY, axis=(0,1,2))\n",
    "\n",
    "    \n",
    "    #================== dW ==================\n",
    "    dW_col = np.dot(X_col.T, dY_col)\n",
    "    dW = dW_col.reshape(C_in, H_filter, W_filter, C_out).transpose(1, 2, 0, 3)\n",
    "\n",
    "\n",
    "    #================== dX ==================\n",
    "    dX_col = np.dot(dY_col, W_col.T)\n",
    "    dX = np.zeros((N_batch, H_in+2*P, W_in+2*P, C_in))\n",
    "    dX_col_row_index = 0\n",
    "    for n_batch in range(N_batch):\n",
    "        for h in range(H_out):\n",
    "            for w in range(W_out):\n",
    "                h_start = h * S\n",
    "                h_end   = h_start + H_filter\n",
    "                w_start = w * S\n",
    "                w_end   = w_start + W_filter\n",
    "\n",
    "                dX_col_slice = dX_col[dX_col_row_index, :]\n",
    "                dX[n_batch, h_start:h_end, w_start:w_end, :] += dX_col_slice.reshape(C_in, H_filter, W_filter).transpose(1, 2, 0)\n",
    "\n",
    "                dX_col_row_index += 1 # dX_col_row_index = n_batch * (H_out * W_out) + h * W_out + w\n",
    "\n",
    "    if P > 0:\n",
    "        dX = dX[:, P:-P, P:-P, :]\n",
    "    \n",
    "    return (dX, dW, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matched? ===\n",
      "dX:  True 1.71279033933e-08\n",
      "dW:  True 9.32435609026e-08\n",
      "db:  True 0.0\n"
     ]
    }
   ],
   "source": [
    "P = 1\n",
    "S = 2\n",
    "X = np.random.randn(3, 7, 7, 3).astype(np.float32)\n",
    "W = np.random.randn(3,3,3,4).astype(np.float32)\n",
    "b = np.random.randn(4).astype(np.float32)\n",
    "\n",
    "dY = np.ones((3,4,4,4))\n",
    "dX, dW, db = conv_backward(dY, X, W, b, P, S)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X)\n",
    "    tf_W = tf.Variable(W)\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, S, S, 1], padding='SAME') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW, tf_db = sess.run(tf_grad)\n",
    "        \n",
    "check_dX = np.linalg.norm(dX - tf_dX) / (np.linalg.norm(dX) + np.linalg.norm(tf_dX))\n",
    "check_dW = np.linalg.norm(dW - tf_dW) / (np.linalg.norm(dW) + np.linalg.norm(tf_dW))\n",
    "check_db = np.linalg.norm(db - tf_db) / (np.linalg.norm(db) + np.linalg.norm(tf_db))\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", check_dX < 1e-7, check_dX)\n",
    "print(\"dW: \", check_dW < 1e-7, check_dW)\n",
    "print(\"db: \", check_db < 1e-7, check_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matched? ===\n",
      "dX:  True 6.78232892095e-08\n",
      "dW:  False 4.23263412303e-07\n",
      "db:  True 0.0\n"
     ]
    }
   ],
   "source": [
    "P = 1\n",
    "S = 1\n",
    "X = np.random.randn(128, 28, 28, 3).astype(np.float32)\n",
    "W = np.random.randn(3, 3, 3, 16).astype(np.float32)\n",
    "b = np.random.randn(16).astype(np.float32)\n",
    "\n",
    "\n",
    "dY = np.ones((128, 28, 28, 16))\n",
    "dX, dW, db = conv_backward(dY, X, W, b, P, S)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X)\n",
    "    tf_W = tf.Variable(W)\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, S, S, 1], padding='SAME') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW, tf_db = sess.run(tf_grad)\n",
    "        \n",
    "check_dX = np.linalg.norm(dX - tf_dX) / (np.linalg.norm(dX) + np.linalg.norm(tf_dX))\n",
    "check_dW = np.linalg.norm(dW - tf_dW) / (np.linalg.norm(dW) + np.linalg.norm(tf_dW))\n",
    "check_db = np.linalg.norm(db - tf_db) / (np.linalg.norm(db) + np.linalg.norm(tf_db))\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", check_dX < 1e-7, check_dX)\n",
    "print(\"dW: \", check_dW < 1e-7, check_dW)\n",
    "print(\"db: \", check_db < 1e-7, check_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693 ms ± 858 µs per loop (mean ± std. dev. of 3 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n3 -r3\n",
    "\n",
    "conv_backward(dY, X, W, b, P, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Shape Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00315870523616\n",
      "13703.7215824\n",
      "13703.7\n",
      "=== Matched? ===\n",
      "dX:  True 9.91269930045e-08\n",
      "dW:  True 1.15249913356e-07\n",
      "db:  True 0.0\n"
     ]
    }
   ],
   "source": [
    "P = 3\n",
    "S = 1\n",
    "X = np.random.randn(64, 11, 9, 16).astype(np.float32)\n",
    "W = np.random.randn(7, 7, 16, 32).astype(np.float32)\n",
    "b = np.random.randn(32).astype(np.float32)\n",
    "\n",
    "dY = np.ones((64, 11, 9, 32))\n",
    "dX, dW, db = conv_backward(dY, X, W, b, P, S)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X)\n",
    "    tf_W = tf.constant(W)\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, S, S, 1], padding='SAME') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_grad_val = sess.run(tf_grad)\n",
    "    \n",
    "    tf_dX = tf_grad_val[0]\n",
    "    tf_dW = tf_grad_val[1]\n",
    "    tf_db = tf_grad_val[2]\n",
    "\n",
    "check_dX = np.linalg.norm(dX - tf_dX) / (np.linalg.norm(dX) + np.linalg.norm(tf_dX))\n",
    "check_dW = np.linalg.norm(dW - tf_dW) / (np.linalg.norm(dW) + np.linalg.norm(tf_dW))\n",
    "check_db = np.linalg.norm(db - tf_db) / (np.linalg.norm(db) + np.linalg.norm(tf_db))\n",
    "\n",
    "print(np.linalg.norm(dW - tf_dW))\n",
    "print(np.linalg.norm(dW))\n",
    "print(np.linalg.norm(tf_dW))\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", check_dX < 1e-6, check_dX)\n",
    "print(\"dW: \", check_dW < 1e-6, check_dW)\n",
    "print(\"db: \", check_db < 1e-6, check_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000250347131214\n",
      "2144.87415455\n",
      "2144.87\n",
      "=== Matched? ===\n",
      "dX:  True 2.54974839091e-08\n",
      "dW:  True 5.83594003252e-08\n",
      "db:  True 0.0\n"
     ]
    }
   ],
   "source": [
    "P = 0\n",
    "S = 5\n",
    "X = np.random.randn(4, 28, 46, 128).astype(np.float32)\n",
    "W = np.random.randn(8, 16, 128, 2).astype(np.float32)\n",
    "b = np.random.randn(2).astype(np.float32)\n",
    "\n",
    "dY = np.ones((4, 5, 7, 2))\n",
    "dX, dW, db = conv_backward(dY, X, W, b, P, S)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X)\n",
    "    tf_W = tf.constant(W)\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, S, S, 1], padding='VALID') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_grad_val = sess.run(tf_grad)\n",
    "    \n",
    "    tf_dX = tf_grad_val[0]\n",
    "    tf_dW = tf_grad_val[1]\n",
    "    tf_db = tf_grad_val[2]\n",
    "\n",
    "check_dX = np.linalg.norm(dX - tf_dX) / (np.linalg.norm(dX) + np.linalg.norm(tf_dX))\n",
    "check_dW = np.linalg.norm(dW - tf_dW) / (np.linalg.norm(dW) + np.linalg.norm(tf_dW))\n",
    "check_db = np.linalg.norm(db - tf_db) / (np.linalg.norm(db) + np.linalg.norm(tf_db))\n",
    "\n",
    "print(np.linalg.norm(dW - tf_dW))\n",
    "print(np.linalg.norm(dW))\n",
    "print(np.linalg.norm(tf_dW))\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", check_dX < 1e-6, check_dX)\n",
    "print(\"dW: \", check_dW < 1e-6, check_dW)\n",
    "print(\"db: \", check_db < 1e-6, check_db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
