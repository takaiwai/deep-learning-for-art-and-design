{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07-05: Efficient Convolution Backward Pass using col2im\n",
    "\n",
    "Try calculating with NumPy, then check with TensorFlow's autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Basic 2D Convolution\n",
    "$(4 \\times 4) * (3 \\times 3) = (2 \\times 2)$\n",
    "\n",
    "#### 2. Padding\n",
    "$(4 \\times 4) * (3 \\times 3) = (4 \\times 4)$ where $P=1$\n",
    "\n",
    "#### 3. Stride\n",
    "$(7 \\times 7) * (3 \\times 3) = (3 \\times 3)$ where $S=2$\n",
    "\n",
    "#### 4. Padding and Stride\n",
    "$(7 \\times 7) * (3 \\times 3) = (4 \\times 4)$ where $P=1, S=2$\n",
    "\n",
    "#### 5. Channel\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3) = (2 \\times 2)$\n",
    "\n",
    "#### 6. Channel and bias \n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3) + (1) = (2 \\times 2)$\n",
    "\n",
    "#### 7. Multiple Filters\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) = (2 \\times 2 \\times 4)$\n",
    "\n",
    "#### 8.Multiple Filters + bias \n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (2 \\times 2 \\times 4)$\n",
    "\n",
    "#### 9. Mini-batch + bias\n",
    "$(3 \\times 4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (3 \\times 2 \\times 2 \\times 4)$\n",
    "\n",
    "#### 10. RGB Mini-batch $*$ Multiple Filters with stride and padding\n",
    "$(3 \\times 7 \\times 7 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (3 \\times 4 \\times 4 \\times 4)$ where $P=1, S=2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def float_sequence(size):\n",
    "    return np.arange(size, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Basic Convolution Backward\n",
    "\n",
    "$(4 \\times 4) * (3 \\times 3) = (2 \\times 2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== dY ===\n",
      "[[ 1.  1.]\n",
      " [ 1.  1.]]\n",
      "=== dX ===\n",
      "[[ 12.  23.  21.  10.]\n",
      " [ 21.  40.  36.  17.]\n",
      " [ 15.  28.  24.  11.]\n",
      " [  6.  11.   9.   4.]]\n",
      "=== dW ===\n",
      "[[ 10.  14.  18.]\n",
      " [ 26.  30.  34.]\n",
      " [ 42.  46.  50.]]\n",
      "=== L (tf) ===\n",
      "1848.0\n",
      "=== dX (tf) ===\n",
      "[[ 12.  23.  21.  10.]\n",
      " [ 21.  40.  36.  17.]\n",
      " [ 15.  28.  24.  11.]\n",
      " [  6.  11.   9.   4.]]\n",
      "=== dW (tf) ===\n",
      "[[ 10.  14.  18.]\n",
      " [ 26.  30.  34.]\n",
      " [ 42.  46.  50.]]\n",
      "=== Matched? ===\n",
      "dX:  True\n",
      "dY:  True\n"
     ]
    }
   ],
   "source": [
    "X = float_sequence(4*4).reshape(4,4)\n",
    "W = 12 - float_sequence(3*3).reshape(3,3)\n",
    "\n",
    "dY = np.ones((2,2))\n",
    "\n",
    "print(\"=== dY ===\")     \n",
    "print(dY)\n",
    "\n",
    "dX = np.zeros((4,4))\n",
    "dW = np.zeros((3,3))\n",
    "\n",
    "for h in range(4-3+1):\n",
    "    for w in range(4-3+1):\n",
    "        h_start = h\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        current_dY = dY[h, w]\n",
    "        dX[h_start:h_end, w_start:w_end] += current_dY * W\n",
    "        dW += current_dY * X[h_start:h_end, w_start:w_end]\n",
    "        \n",
    "print(\"=== dX ===\")     \n",
    "print(dX)\n",
    "        \n",
    "print(\"=== dW ===\")     \n",
    "print(dW)\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 4, 4, 1))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 1, 1))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "    print(\"=== L (tf) ===\")     \n",
    "    print(tf_L_val)\n",
    "    print(\"=== dX (tf) ===\")     \n",
    "    print(tf_dX[0, :, :, 0])\n",
    "    print(\"=== dW (tf) ===\")     \n",
    "    print(tf_dW[:, :, 0, 0])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, 0]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convolution with padding\n",
    "\n",
    "$(4 \\times 4) * (3 \\times 3) = (4 \\times 4)$ where $P=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== dX ===\n",
      "[[ 40.  57.  57.  36.]\n",
      " [ 51.  72.  72.  45.]\n",
      " [ 51.  72.  72.  45.]\n",
      " [ 28.  39.  39.  24.]]\n",
      "=== dW ===\n",
      "[[  45.   66.   54.]\n",
      " [  84.  120.   96.]\n",
      " [  81.  114.   90.]]\n",
      "=== dX (tf) ===\n",
      "[[ 40.  57.  57.  36.]\n",
      " [ 51.  72.  72.  45.]\n",
      " [ 51.  72.  72.  45.]\n",
      " [ 28.  39.  39.  24.]]\n",
      "=== dW (tf) ===\n",
      "[[  45.   66.   54.]\n",
      " [  84.  120.   96.]\n",
      " [  81.  114.   90.]]\n",
      "=== Matched? ===\n",
      "dX:  True\n",
      "dY:  True\n"
     ]
    }
   ],
   "source": [
    "X_org = float_sequence(4*4).reshape(4,4)\n",
    "P = 1\n",
    "X = np.pad(X_org, ((P, P), (P, P)), 'constant')\n",
    "W = 12 - float_sequence(3*3).reshape(3,3)\n",
    "\n",
    "dY = np.ones((4,4))\n",
    "\n",
    "dX = np.zeros((6,6))\n",
    "dW = np.zeros((3,3))\n",
    "\n",
    "for h in range(4):\n",
    "    for w in range(4):\n",
    "        h_start = h\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        current_dY = dY[h, w]\n",
    "        dX[h_start:h_end, w_start:w_end] += current_dY * W\n",
    "        dW += current_dY * X[h_start:h_end, w_start:w_end]\n",
    "\n",
    "dX = dX[P:-P, P:-P] # unpad\n",
    "print(\"=== dX ===\")\n",
    "print(dX)\n",
    "        \n",
    "print(\"=== dW ===\")     \n",
    "print(dW)\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X_org.reshape(1, 4, 4, 1))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 1, 1))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "    print(\"=== dX (tf) ===\")     \n",
    "    print(tf_dX[0, :, :, 0])\n",
    "    print(\"=== dW (tf) ===\")     \n",
    "    print(tf_dW[:, :, 0, 0])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, 0]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convolution with Stride\n",
    "\n",
    "$(7 \\times 7) * (3 \\times 3) = (3 \\times 3)$ where $S=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== dX ===\n",
      "[[ 12.  11.  22.  11.  22.  11.  10.]\n",
      " [  9.   8.  16.   8.  16.   8.   7.]\n",
      " [ 18.  16.  32.  16.  32.  16.  14.]\n",
      " [  9.   8.  16.   8.  16.   8.   7.]\n",
      " [ 18.  16.  32.  16.  32.  16.  14.]\n",
      " [  9.   8.  16.   8.  16.   8.   7.]\n",
      " [  6.   5.  10.   5.  10.   5.   4.]]\n",
      "=== dW ===\n",
      "[[ 144.  153.  162.]\n",
      " [ 207.  216.  225.]\n",
      " [ 270.  279.  288.]]\n",
      "=== L (tf) ===\n",
      "14364.0\n",
      "=== dX (tf) ===\n",
      "[[ 12.  11.  22.  11.  22.  11.  10.]\n",
      " [  9.   8.  16.   8.  16.   8.   7.]\n",
      " [ 18.  16.  32.  16.  32.  16.  14.]\n",
      " [  9.   8.  16.   8.  16.   8.   7.]\n",
      " [ 18.  16.  32.  16.  32.  16.  14.]\n",
      " [  9.   8.  16.   8.  16.   8.   7.]\n",
      " [  6.   5.  10.   5.  10.   5.   4.]]\n",
      "=== dW (tf) ===\n",
      "[[ 144.  153.  162.]\n",
      " [ 207.  216.  225.]\n",
      " [ 270.  279.  288.]]\n",
      "=== Matched? ===\n",
      "dX:  True\n",
      "dY:  True\n"
     ]
    }
   ],
   "source": [
    "X = float_sequence(7*7).reshape(7,7)\n",
    "W = 12 - float_sequence(3*3).reshape(3,3)\n",
    "S = 2\n",
    "\n",
    "dY = np.ones((3,3))\n",
    "\n",
    "dX = np.zeros((7,7))\n",
    "dW = np.zeros((3,3))\n",
    "\n",
    "for h in range(3):\n",
    "    for w in range(3):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        current_dY = dY[h, w]\n",
    "        dX[h_start:h_end, w_start:w_end] += current_dY * W\n",
    "        dW += current_dY * X[h_start:h_end, w_start:w_end]\n",
    "        \n",
    "print(\"=== dX ===\")     \n",
    "print(dX)\n",
    "        \n",
    "print(\"=== dW ===\")     \n",
    "print(dW)\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 7, 7, 1))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 1, 1))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, S, S, 1], padding='VALID')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "    print(\"=== L (tf) ===\")     \n",
    "    print(tf_L_val)\n",
    "    print(\"=== dX (tf) ===\")     \n",
    "    print(tf_dX[0, :, :, 0])\n",
    "    print(\"=== dW (tf) ===\")     \n",
    "    print(tf_dW[:, :, 0, 0])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, 0]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Padding and Stride\n",
    "\n",
    "$(7 \\times 7) * (3 \\times 3) = (4 \\times 4)$ where $P=1, S=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== dX ===\n",
      "[[  8.  16.   8.  16.   8.  16.   8.]\n",
      " [ 16.  32.  16.  32.  16.  32.  16.]\n",
      " [  8.  16.   8.  16.   8.  16.   8.]\n",
      " [ 16.  32.  16.  32.  16.  32.  16.]\n",
      " [  8.  16.   8.  16.   8.  16.   8.]\n",
      " [ 16.  32.  16.  32.  16.  32.  16.]\n",
      " [  8.  16.   8.  16.   8.  16.   8.]]\n",
      "=== dW ===\n",
      "[[ 216.  288.  216.]\n",
      " [ 288.  384.  288.]\n",
      " [ 216.  288.  216.]]\n",
      "=== L (tf) ===\n",
      "19200.0\n",
      "=== dX (tf) ===\n",
      "[[  8.  16.   8.  16.   8.  16.   8.]\n",
      " [ 16.  32.  16.  32.  16.  32.  16.]\n",
      " [  8.  16.   8.  16.   8.  16.   8.]\n",
      " [ 16.  32.  16.  32.  16.  32.  16.]\n",
      " [  8.  16.   8.  16.   8.  16.   8.]\n",
      " [ 16.  32.  16.  32.  16.  32.  16.]\n",
      " [  8.  16.   8.  16.   8.  16.   8.]]\n",
      "=== dW (tf) ===\n",
      "[[ 216.  288.  216.]\n",
      " [ 288.  384.  288.]\n",
      " [ 216.  288.  216.]]\n",
      "dX:  True\n",
      "dY:  True\n"
     ]
    }
   ],
   "source": [
    "P = 1\n",
    "S = 2\n",
    "X_org = float_sequence(7*7).reshape(7,7)\n",
    "X = np.pad(X_org, ((P, P), (P, P)), 'constant')\n",
    "W = 12 - float_sequence(3*3).reshape(3,3)\n",
    "\n",
    "# print(\"=== X ===\")\n",
    "# print(X)\n",
    "# print(\"=== W ===\")\n",
    "# print(W)\n",
    "\n",
    "dY = np.ones((4,4))\n",
    "\n",
    "dX = np.zeros((9,9))\n",
    "dW = np.zeros((3,3))\n",
    "\n",
    "for h in range(4):\n",
    "    for w in range(4):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        current_dY = dY[h, w]\n",
    "        dX[h_start:h_end, w_start:w_end] += current_dY * W\n",
    "        dW += current_dY * X[h_start:h_end, w_start:w_end]\n",
    "\n",
    "dX = dX[P:-P, P:-P] # unpad\n",
    "print(\"=== dX ===\")     \n",
    "print(dX)\n",
    "        \n",
    "print(\"=== dW ===\")     \n",
    "print(dW)\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X_org.reshape(1, 7, 7, 1))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 1, 1))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, S, S, 1], padding='SAME')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "    print(\"=== L (tf) ===\")     \n",
    "    print(tf_L_val)\n",
    "    print(\"=== dX (tf) ===\")     \n",
    "    print(tf_dX[0, :, :, 0])\n",
    "    print(\"=== dW (tf) ===\")     \n",
    "    print(tf_dW[:, :, 0, 0])\n",
    "\n",
    "# print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, 0]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Channel\n",
    "\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3) = (2 \\times 2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== L (tf) ===\n",
      "34650.0\n",
      "=== dX (tf) ===\n",
      "[[[ 30.  29.  28.]\n",
      "  [ 57.  55.  53.]\n",
      "  [ 51.  49.  47.]\n",
      "  [ 24.  23.  22.]]\n",
      "\n",
      " [[ 51.  49.  47.]\n",
      "  [ 96.  92.  88.]\n",
      "  [ 84.  80.  76.]\n",
      "  [ 39.  37.  35.]]\n",
      "\n",
      " [[ 33.  31.  29.]\n",
      "  [ 60.  56.  52.]\n",
      "  [ 48.  44.  40.]\n",
      "  [ 21.  19.  17.]]\n",
      "\n",
      " [[ 12.  11.  10.]\n",
      "  [ 21.  19.  17.]\n",
      "  [ 15.  13.  11.]\n",
      "  [  6.   5.   4.]]]\n",
      "=== Matched? ===\n",
      "dX:  True\n",
      "dY:  True\n"
     ]
    }
   ],
   "source": [
    "X = float_sequence(4*4*3).reshape(4,4,3)\n",
    "W = 30 - float_sequence(3*3*3).reshape(3,3,3)\n",
    "# print(\"=== X ===\")\n",
    "# print(X.transpose(2, 0, 1))\n",
    "# print(\"=== W ===\")\n",
    "# print(W.transpose(2, 0, 1))\n",
    "\n",
    "dY = np.ones((2,2))\n",
    "\n",
    "# print(\"=== dY ===\")     \n",
    "# print(dY)\n",
    "\n",
    "dX = np.zeros((4,4,3))\n",
    "dW = np.zeros((3,3,3))\n",
    "\n",
    "for h in range(4-3+1):\n",
    "    for w in range(4-3+1):\n",
    "        h_start = h\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        current_dY = dY[h, w]\n",
    "        dX[h_start:h_end, w_start:w_end, :] += current_dY * W\n",
    "        dW += current_dY * X[h_start:h_end, w_start:w_end, :]\n",
    "        \n",
    "# print(\"=== dX ===\")     \n",
    "# print(dX)\n",
    "        \n",
    "# print(\"=== dW ===\")     \n",
    "# print(dW)\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 4, 4, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 1))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "    print(\"=== L (tf) ===\")     \n",
    "    print(tf_L_val)\n",
    "    print(\"=== dX (tf) ===\")     \n",
    "    print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, 0])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, :]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, :, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Channel and bias \n",
    "\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3) + (1) = (2 \\times 2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== db ===\n",
      "4.0\n",
      "=== db (tf) ===\n",
      "4.0\n",
      "=== Matched? ===\n",
      "dX:  True\n",
      "dY:  True\n",
      "db:  True\n"
     ]
    }
   ],
   "source": [
    "X = float_sequence(4*4*3).reshape(4,4,3)\n",
    "W = 30 - float_sequence(3*3*3).reshape(3,3,3)\n",
    "b = np.array([10], dtype=np.float32)\n",
    "# print(\"=== X ===\")\n",
    "# print(X.transpose(2, 0, 1))\n",
    "# print(\"=== W ===\")\n",
    "# print(W.transpose(2, 0, 1))\n",
    "\n",
    "dY = np.ones((2,2))\n",
    "\n",
    "# print(\"=== dY ===\")     \n",
    "# print(dY)\n",
    "\n",
    "\n",
    "db = np.sum(dY)\n",
    "dX = np.zeros((4,4,3))\n",
    "dW = np.zeros((3,3,3))\n",
    "\n",
    "for h in range(4-3+1):\n",
    "    for w in range(4-3+1):\n",
    "        h_start = h\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        current_dY = dY[h, w]\n",
    "        dX[h_start:h_end, w_start:w_end, :] += current_dY * W\n",
    "        dW += current_dY * X[h_start:h_end, w_start:w_end, :]\n",
    "        \n",
    "# print(\"=== dX ===\")     \n",
    "# print(dX)\n",
    "        \n",
    "# print(\"=== dW ===\")     \n",
    "# print(dW)\n",
    "\n",
    "print(\"=== db ===\")     \n",
    "print(db)\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 4, 4, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 1))\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW, tf_db = sess.run(tf_grad)\n",
    "#     print(\"=== L (tf) ===\")     \n",
    "#     print(tf_L_val)\n",
    "#     print(\"=== dX (tf) ===\")     \n",
    "#     print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, 0])\n",
    "    print(\"=== db (tf) ===\")     \n",
    "    print(tf_db[0])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, :]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, :, 0]))\n",
    "print(\"db: \", np.all(db == tf_db[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Multiple Filters\n",
    "\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) = (2 \\times 2 \\times 4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matched? ===\n",
      "dX:  True\n",
      "dY:  True\n"
     ]
    }
   ],
   "source": [
    "X = float_sequence(4*4*3).reshape(4,4,3)\n",
    "W = 120 - float_sequence(3*3*3*4).reshape(3,3,3,4)\n",
    "\n",
    "\n",
    "dY = np.ones((2,2,4))\n",
    "\n",
    "dX = np.zeros((4,4,3))\n",
    "dW = np.zeros((3,3,3,4))\n",
    "\n",
    "for h in range(4-3+1):\n",
    "    for w in range(4-3+1):\n",
    "        h_start = h\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        for c_out in range(4):\n",
    "            current_dY = dY[h, w, c_out]\n",
    "            dX[h_start:h_end, w_start:w_end, :] += current_dY * W[:, :, :, c_out]\n",
    "            dW[:, :, :, c_out] += current_dY * X[h_start:h_end, w_start:w_end, :]\n",
    "        \n",
    "# print(\"=== dX ===\")     \n",
    "# print(dX)\n",
    "        \n",
    "# print(\"=== dW ===\")     \n",
    "# print(dW)\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 4, 4, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 4))\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW = sess.run(tf_grad)\n",
    "#     print(\"=== L (tf) ===\")     \n",
    "#     print(tf_L_val)\n",
    "#     print(\"=== dX (tf) ===\")     \n",
    "#     print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, :])\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, :]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, :, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Multiple Filters + bias \n",
    "\n",
    "$(4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (2 \\times 2 \\times 4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== db ===\n",
      "[ 4.  4.  4.  4.]\n",
      "=== db (tf) ===\n",
      "[ 4.  4.  4.  4.]\n",
      "=== Matched? ===\n",
      "dX:  True\n",
      "dY:  True\n",
      "db:  True\n"
     ]
    }
   ],
   "source": [
    "X = float_sequence(4*4*3).reshape(4,4,3)\n",
    "W = 120 - float_sequence(3*3*3*4).reshape(3,3,3,4)\n",
    "b = np.array([10, 100, 1000, 10000], dtype=np.float32)\n",
    "\n",
    "dY = np.ones((2,2,4))\n",
    "\n",
    "db = np.sum(dY, axis=(0,1))\n",
    "dX = np.zeros((4,4,3))\n",
    "dW = np.zeros((3,3,3,4))\n",
    "\n",
    "for h in range(4-3+1):\n",
    "    for w in range(4-3+1):\n",
    "        h_start = h\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        for c_out in range(4):\n",
    "            current_dY = dY[h, w, c_out]\n",
    "            dX[h_start:h_end, w_start:w_end, :] += current_dY * W[:, :, :, c_out]\n",
    "            dW[:, :, :, c_out] += current_dY * X[h_start:h_end, w_start:w_end, :]\n",
    "        \n",
    "# print(\"=== dX ===\")     \n",
    "# print(dX)\n",
    "        \n",
    "# print(\"=== dW ===\")     \n",
    "# print(dW)\n",
    "\n",
    "print(\"=== db ===\")     \n",
    "print(db)\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(1, 4, 4, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 4))\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW, tf_db = sess.run(tf_grad)\n",
    "#     print(\"=== L (tf) ===\")     \n",
    "#     print(tf_L_val)\n",
    "#     print(\"=== dX (tf) ===\")     \n",
    "#     print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, :])\n",
    "    print(\"=== db (tf) ===\")     \n",
    "    print(tf_db)\n",
    "\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[0, :, :, :]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, :, :]))\n",
    "print(\"db: \", np.all(db == tf_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Mini-batch + bias\n",
    "\n",
    "$(3 \\times 4 \\times 4 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (3 \\times 2 \\times 2 \\times 4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matched? ===\n",
      "dX:  True\n",
      "dY:  True\n",
      "db:  True\n"
     ]
    }
   ],
   "source": [
    "X = float_sequence(3*4*4*3).reshape(3,4,4,3)\n",
    "W = 120 - float_sequence(3*3*3*4).reshape(3,3,3,4)\n",
    "b = np.array([10, 100, 1000, 10000], dtype=np.float32)\n",
    "\n",
    "dY = np.ones((3,2,2,4))\n",
    "\n",
    "db = np.sum(dY, axis=(0,1,2))\n",
    "dX = np.zeros((3,4,4,3))\n",
    "dW = np.zeros((3,3,3,4))\n",
    "\n",
    "for h in range(4-3+1):\n",
    "    for w in range(4-3+1):\n",
    "        h_start = h\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        for n_batch in range(3):\n",
    "            for c_out in range(4):\n",
    "                current_dY = dY[n_batch, h, w, c_out]\n",
    "                dX[n_batch, h_start:h_end, w_start:w_end, :] += current_dY * W[:, :, :, c_out]\n",
    "                dW[:, :, :, c_out] += current_dY * X[n_batch, h_start:h_end, w_start:w_end, :]\n",
    "        \n",
    "# print(\"=== dX ===\")     \n",
    "# print(dX)\n",
    "        \n",
    "# print(\"=== dW ===\")     \n",
    "# print(dW)\n",
    "\n",
    "# print(\"=== db ===\")     \n",
    "# print(db)\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X.reshape(3, 4, 4, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 4))\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, 1, 1, 1], padding='VALID') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW, tf_db = sess.run(tf_grad)\n",
    "#     print(\"=== L (tf) ===\")     \n",
    "#     print(tf_L_val)\n",
    "#     print(\"=== dX (tf) ===\")     \n",
    "#     print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, :])\n",
    "#     print(\"=== db (tf) ===\")     \n",
    "#     print(tf_db)\n",
    "\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[:, :, :, :]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, :, :]))\n",
    "print(\"db: \", np.all(db == tf_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. RGB Mini-batch $*$ Multiple Filters with stride and padding\n",
    "$(3 \\times 7 \\times 7 \\times 3) * (3 \\times 3 \\times 3 \\times 4) + (4)= (3 \\times 4 \\times 4 \\times 4)$ where $P=1, S=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matched? ===\n",
      "dX:  True\n",
      "dY:  True\n",
      "db:  True\n"
     ]
    }
   ],
   "source": [
    "P = 1\n",
    "S = 2\n",
    "X_org = float_sequence(3*7*7*3).reshape(3,7,7,3)\n",
    "X = np.pad(X_org, ((0, 0), (P, P), (P, P), (0, 0)), 'constant')\n",
    "W = 120 - float_sequence(3*3*3*4).reshape(3,3,3,4)\n",
    "b = np.array([10, 100, 1000, 10000], dtype=np.float32)\n",
    "\n",
    "dY = np.ones((3,4,4,4))\n",
    "\n",
    "db = np.sum(dY, axis=(0,1,2))\n",
    "dX = np.zeros((3,9,9,3))\n",
    "dW = np.zeros((3,3,3,4))\n",
    "\n",
    "for h in range(4):\n",
    "    for w in range(4):\n",
    "        h_start = h * S\n",
    "        h_end   = h_start + 3\n",
    "        w_start = w * S\n",
    "        w_end   = w_start + 3\n",
    "        \n",
    "        for n_batch in range(3):\n",
    "            for c_out in range(4):\n",
    "                current_dY = dY[n_batch, h, w, c_out]\n",
    "                dX[n_batch, h_start:h_end, w_start:w_end, :] += current_dY * W[:, :, :, c_out]\n",
    "                dW[:, :, :, c_out] += current_dY * X[n_batch, h_start:h_end, w_start:w_end, :]\n",
    "\n",
    "dX = dX[:, P:-P, P:-P, :] # unpad\n",
    "# print(\"=== dX ===\")     \n",
    "# print(dX)\n",
    "        \n",
    "# print(\"=== dW ===\")     \n",
    "# print(dW)\n",
    "\n",
    "# print(\"=== db ===\")     \n",
    "# print(db)\n",
    "\n",
    "\n",
    "#================== tf ==================\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X_org.reshape(3, 7, 7, 3))\n",
    "    tf_W = tf.Variable(W.reshape(3, 3, 3, 4))\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, S, S, 1], padding='SAME') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW, tf_db = sess.run(tf_grad)\n",
    "#     print(\"=== L (tf) ===\")     \n",
    "#     print(tf_L_val)\n",
    "#     print(\"=== dX (tf) ===\")     \n",
    "#     print(tf_dX[0, :, :, :])\n",
    "#     print(\"=== dW (tf) ===\")     \n",
    "#     print(tf_dW[:, :, :, :])\n",
    "#     print(\"=== db (tf) ===\")     \n",
    "#     print(tf_db)\n",
    "\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", np.all(dX == tf_dX[:, :, :, :]))\n",
    "print(\"dY: \", np.all(dW == tf_dW[:, :, :, :]))\n",
    "print(\"db: \", np.all(db == tf_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized naive convolution backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_naive_backward(dY, X, W, b, P=0, S=1):\n",
    "    N_batch, H_in, W_in, C_in = X.shape\n",
    "    H_filter, W_filter, _, C_out = W.shape\n",
    "    _, H_out, W_out, _ = dY.shape\n",
    "    \n",
    "    if P > 0:\n",
    "        X = np.pad(X, ((0, 0), (P, P), (P, P), (0, 0)), 'constant')\n",
    "    \n",
    "    db = np.sum(dY, axis=(0,1,2))\n",
    "    dX = np.zeros((N_batch, H_in+2*P, W_in+2*P, C_in))\n",
    "    dW = np.zeros_like(W)\n",
    "\n",
    "    for w in range(W_out):\n",
    "        for h in range(H_out):\n",
    "            h_start = h * S\n",
    "            h_end   = h_start + H_filter\n",
    "            w_start = w * S\n",
    "            w_end   = w_start + W_filter\n",
    "\n",
    "            for n_batch in range(N_batch):\n",
    "                for c_out in range(C_out):\n",
    "                    current_dY = dY[n_batch, h, w, c_out]\n",
    "                    dX[n_batch, h_start:h_end, w_start:w_end, :] += current_dY * W[:, :, :, c_out]\n",
    "                    dW[:, :, :, c_out] += current_dY * X[n_batch, h_start:h_end, w_start:w_end, :]\n",
    "\n",
    "    dX = dX[:, P:-P, P:-P, :]\n",
    "    \n",
    "    return (dX, dW, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Matched? ===\n",
      "dX:  True 2.14135281647e-08\n",
      "dW:  True 5.97622e-08\n",
      "db:  True 0.0\n"
     ]
    }
   ],
   "source": [
    "P = 1\n",
    "S = 2\n",
    "X = np.random.randn(3, 7, 7, 3).astype(np.float32)\n",
    "W = np.random.randn(3,3,3,4).astype(np.float32)\n",
    "b = np.random.randn(4).astype(np.float32)\n",
    "\n",
    "dY = np.ones((3,4,4,4))\n",
    "dX, dW, db = conv_naive_backward(dY, X, W, b, P, S)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf_X = tf.constant(X)\n",
    "    tf_W = tf.Variable(W)\n",
    "    tf_b = tf.constant(b)\n",
    "    tf_Y = tf.nn.conv2d(tf_X, tf_W, strides=[1, S, S, 1], padding='SAME') + tf_b\n",
    "    tf_L = tf.reduce_sum(tf_Y)\n",
    "    tf_grad = tf.gradients(tf_L, [tf_X, tf_W, tf_b])\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf_L_val = sess.run(tf_L)\n",
    "    tf_dX, tf_dW, tf_db = sess.run(tf_grad)\n",
    "        \n",
    "check_dX = np.linalg.norm(dX - tf_dX) / (np.linalg.norm(dX) + np.linalg.norm(tf_dX))\n",
    "check_dW = np.linalg.norm(dW - tf_dW) / (np.linalg.norm(dW) + np.linalg.norm(tf_dW))\n",
    "check_db = np.linalg.norm(db - tf_db) / (np.linalg.norm(db) + np.linalg.norm(tf_db))\n",
    "\n",
    "print(\"=== Matched? ===\")    \n",
    "print(\"dX: \", check_dX < 1e-7, check_dX)\n",
    "print(\"dW: \", check_dW < 1e-7, check_dW)\n",
    "print(\"db: \", check_db < 1e-7, check_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
